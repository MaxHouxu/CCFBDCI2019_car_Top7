{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "# import shap\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os \n",
    "import gc\n",
    "from tqdm import tqdm, tqdm_notebook \n",
    "from sklearn.model_selection import StratifiedKFold, KFold\n",
    "from sklearn.metrics import f1_score, roc_auc_score\n",
    "from sklearn.metrics import mean_squared_error as mse\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import datetime\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import lightgbm as lgb\n",
    "from sklearn.cluster import KMeans\n",
    "import xgboost as xgb\n",
    "from sklearn.externals import joblib\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_sales  = pd.read_csv('data/Train/train_sales_data.csv')\n",
    "train_search = pd.read_csv('data/Train/train_search_data.csv')\n",
    "train_user   = pd.read_csv('data/Train/train_user_reply_data.csv')\n",
    "evaluation_public = pd.read_csv('data/Train/evaluation_public.csv')\n",
    "submit_example    = pd.read_csv('data/Train/submit_example.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "old_model = ['3c974920a76ac9c1','3d7554f1f56dd664','2d0d2c3403909fdb',\n",
    " 'a28bb927b6fcb33c','17bc272c93f19d56','2a2ab41f8f6ff1cb',\n",
    " 'c06a2a387c0ee510','7023efdab9cedc03','af6f4f548684e14d',\n",
    " '7cf283430b3b5e38','d4efbebb087fd03f','7245e0ee27b195cd',\n",
    " '8c915fe4632fb9fa','6155b214590c66e6','28e29f2c03dcd84c',\n",
    " '37aa9169b575ef79','63065128401bb3ff','ea489c253676aafc',\n",
    " 'cd5841d44fd7625e','b25c4e2e3856af22','4a103c30d593fbbe',\n",
    " '7a7885e2d7c00bcf','346393c2c6305fb1','02aab221aabc03b9',\n",
    " '5d7fb682edd0f937','a207df29ec9583f0','b4be3a4917289c82',\n",
    " 'ef76a85c4b39f693','bb9fbec9a2833839','da457d15788fe8ee',\n",
    " '6858d6dfe680bdf7','79de4e4b24c35b04','12f8b7e14947c34d',\n",
    " '04e66e578f653ab9','dff803b4024d261d','61e73e32ad101892',\n",
    " 'a432c483b5beb856','0797526c057dcf5b','936168bd4850913d',\n",
    " 'cc21c7e91a3b5a0c','7aab7fca2470987e','fde95ea242abd896',\n",
    " '97f15de12cfabbd5','f5d69960089c3614','5b1c11c3efed5312',\n",
    " '17363f08d683d52b','06880909932890ca','9c1c7ee8ebdda299',\n",
    " 'c6833cb891626c17','3e21824be728cbec','f8a6975573af1b33',\n",
    " '54fc07138d70374c','212083a9246d2fd3','4f79773e600518a6',\n",
    " 'fc32b1a017b34efe','feabbf46658382b9','f270f6a489c6a9d7',\n",
    " 'd0f245b8781e3631','c6cd4e0e073f5ac2','a9a43d1a7ecbe75d']\n",
    "\n",
    "train_sales = train_sales.iloc[train_sales[train_sales.model.isin(old_model)].index]\n",
    "evaluation_public = evaluation_public.iloc[evaluation_public[evaluation_public.model.isin(old_model)].index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = pd.concat([train_sales, evaluation_public], ignore_index=True)\n",
    "data = data.merge(train_search, 'left', on=['province', 'adcode', 'model', 'regYear', 'regMonth'])\n",
    "data = data.merge(train_user, 'left', on=['model', 'regYear', 'regMonth'])\n",
    "# data=pd.concat([data, k_mean_data], axis=1)\n",
    "data['label'] = data['salesVolume']\n",
    "data['id'] = data['id'].fillna(0).astype(int)\n",
    "data['bodyType'] = data['model'].map(train_sales.drop_duplicates('model').set_index('model')['bodyType'])\n",
    "#LabelEncoder\n",
    "for i in ['bodyType', 'model']:\n",
    "    data[i] = data[i].map(dict(zip(data[i].unique(), range(data[i].nunique()))))\n",
    "data['mt'] = (data['regYear'] - 2016) * 12 + data['regMonth']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_stat_feature(df_,): \n",
    "    df = df_.copy()\n",
    "    stat_feat = []\n",
    "    stat_feat_2=[]\n",
    "    stat_feat_3 = []\n",
    "    stat_feat_4 = []\n",
    "    df['model_adcode'] = df['adcode'] + df['model']\n",
    "    df['model_adcode_mt'] = df['model_adcode'] * 100 + df['mt']\n",
    "    for col in ['label']:\n",
    "        # 历史销量数据特征\n",
    "        for i in [1,2,3,4,5,6,8,9,10,11,12,13,14,15,16]:\n",
    "            stat_feat.append('shift_model_adcode_mt_{}_{}'.format(col,i))\n",
    "            stat_feat_2.append('shift_model_adcode_mt_{}_{}'.format(col,i))\n",
    "            df['model_adcode_mt_{}_{}'.format(col,i)] = df['model_adcode_mt'] + i#新加一列值，等于车型*省*时间+i，寻求i个月前的值，将model_adcode_mt_作为索引\n",
    "            df_last = df[~df[col].isnull()].set_index('model_adcode_mt_{}_{}'.format(col,i))\n",
    "            df['shift_model_adcode_mt_{}_{}'.format(col,i)] = df['model_adcode_mt'].map(df_last[col])#后者索引是31000002开始，前者少i，取前面的匹配后面索引成功，就取值\n",
    "    for col in ['popularity']:\n",
    "        # 历史销量数据特征\n",
    "        for i in [1,2,3,10,11,12]:#popularity只取一部分\n",
    "            stat_feat.append('shift_model_adcode_mt_{}_{}'.format(col,i))\n",
    "            stat_feat_2.append('shift_model_adcode_mt_{}_{}'.format(col,i))\n",
    "            df['model_adcode_mt_{}_{}'.format(col,i)] = df['model_adcode_mt'] + i#新加一列值，等于车型*省*时间+i，寻求i个月前的值，将model_adcode_mt_作为索引\n",
    "            df_last = df[~df[col].isnull()].set_index('model_adcode_mt_{}_{}'.format(col,i))\n",
    "            df['shift_model_adcode_mt_{}_{}'.format(col,i)] = df['model_adcode_mt'].map(df_last[col])#后者索引是31000002开始，前者少i，取前面的匹配后面索引成功，就取值\n",
    "    df[\"increase16_4\"]=(df[\"shift_model_adcode_mt_label_16\"]-df[\"shift_model_adcode_mt_label_4\"])/df[\"shift_model_adcode_mt_label_16\"]#同比一年前的增长\n",
    "    df['mean_province'] = df.groupby([\"model\",\"mt\"]).shift_model_adcode_mt_label_12.transform('mean')\n",
    "    df['min_province'] = df.groupby([\"model\",\"mt\"]).shift_model_adcode_mt_label_12.transform('min')\n",
    "    df['mean_province_15'] = df.groupby([\"model\",\"mt\"]).shift_model_adcode_mt_label_15.transform('mean')\n",
    "    df['mean_province_3'] = df.groupby([\"model\",\"mt\"]).shift_model_adcode_mt_label_3.transform('mean')\n",
    "    df['mean_province_16'] = df.groupby([\"model\",\"mt\"]).shift_model_adcode_mt_label_16.transform('mean')\n",
    "    df['mean_province_4'] = df.groupby([\"model\",\"mt\"]).shift_model_adcode_mt_label_4.transform('mean')\n",
    "    df['mean_Month_15'] = df.groupby([\"adcode\",\"mt\"]).shift_model_adcode_mt_label_15.transform('mean')\n",
    "    df['mean_Month_3'] = df.groupby([\"adcode\",\"mt\"]).shift_model_adcode_mt_label_3.transform('mean')\n",
    "    df['mean_Month_16'] = df.groupby([\"adcode\",\"mt\"]).shift_model_adcode_mt_label_16.transform('mean')\n",
    "    df['mean_Month_4'] = df.groupby([\"adcode\",\"mt\"]).shift_model_adcode_mt_label_4.transform('mean')\n",
    "\n",
    "    df[\"increase_mean_province_16_4\"]=(df[\"mean_province_16\"]-df[\"mean_province_4\"])/df[\"mean_province_16\"]\n",
    "    df[\"increase_mean_province_15_3\"]=(df[\"mean_province_15\"]-df[\"mean_province_3\"])/df[\"mean_province_15\"]\n",
    "    df[\"increase_mean_Month_15_3\"]=(df[\"mean_Month_15\"]-df[\"mean_Month_3\"])/df[\"mean_Month_15\"]\n",
    "    df[\"increase_mean_Month_16_4\"]=(df[\"mean_Month_16\"]-df[\"mean_Month_4\"])/df[\"mean_Month_16\"]\n",
    "    mean=pd.DataFrame(df.groupby([\"adcode\",\"mt\"]).shift_model_adcode_mt_label_12.agg({\"mean_Month\":\"mean\",}))\n",
    "    df=pd.merge(df,mean,on=[\"adcode\",\"mt\"],how=\"left\")\n",
    "\n",
    "    df[\"sum_1\"]=df[\"shift_model_adcode_mt_label_11\"].values+df[\"shift_model_adcode_mt_label_12\"].values+df[\"shift_model_adcode_mt_label_1\"].values+df[\"shift_model_adcode_mt_label_2\"].values\n",
    "    df[\"sum_2\"]=df[\"shift_model_adcode_mt_label_12\"].values+df[\"shift_model_adcode_mt_label_1\"].values\n",
    "    df[\"sum_3\"]=df[\"shift_model_adcode_mt_label_3\"].values+df[\"shift_model_adcode_mt_label_2\"].values+df[\"shift_model_adcode_mt_label_1\"].values\n",
    "    stat_feat_4 = [\"mean_province\",\"min_province\",\"mean_Month\",\"sum_1\",\"sum_2\",\"sum_3\",\"increase16_4\",\n",
    "                   \"increase_mean_province_15_3\",\"increase_mean_Month_15_3\",\"increase_mean_province_16_4\",\"increase_mean_Month_16_4\"]#所有统计特征\n",
    "    stat_feat.remove(\"shift_model_adcode_mt_label_15\")#删掉两个特征\n",
    "    stat_feat.remove(\"shift_model_adcode_mt_label_16\")\n",
    "    return df,stat_feat+stat_feat_3+stat_feat_4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35 35\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\ttraining's l2: 0.0331184\tvalid_1's l2: 0.084129\n",
      "[200]\ttraining's l2: 0.021105\tvalid_1's l2: 0.0774448\n",
      "[300]\ttraining's l2: 0.0161475\tvalid_1's l2: 0.0762927\n",
      "Early stopping, best iteration is:\n",
      "[296]\ttraining's l2: 0.0163232\tvalid_1's l2: 0.0762302\n",
      "0.7459920467745245\n",
      "valid mean: 604.5946242804272\n",
      "true  mean: 616.5537878787878\n",
      "test  mean: 657.9859664471652\n",
      "(1320, 2)\n",
      "35 35\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\ttraining's l2: 0.0342957\tvalid_1's l2: 0.0521189\n",
      "Early stopping, best iteration is:\n",
      "[53]\ttraining's l2: 0.0563297\tvalid_1's l2: 0.0458853\n",
      "0.7549696926552988\n",
      "valid mean: 609.4396653697089\n",
      "true  mean: 673.0143939393939\n",
      "test  mean: 492.5873170178367\n",
      "(1320, 2)\n",
      "35 35\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\ttraining's l2: 0.0342775\tvalid_1's l2: 0.138357\n",
      "[200]\ttraining's l2: 0.0227193\tvalid_1's l2: 0.137469\n",
      "Early stopping, best iteration is:\n",
      "[144]\ttraining's l2: 0.0274144\tvalid_1's l2: 0.136071\n",
      "0.6193718837199853\n",
      "valid mean: 665.2535856170007\n",
      "true  mean: 899.8204545454546\n",
      "test  mean: 592.6573269796879\n",
      "(1320, 2)\n",
      "35 35\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[100]\ttraining's l2: 0.0362034\tvalid_1's l2: 0.004126\n",
      "[200]\ttraining's l2: 0.023995\tvalid_1's l2: 0.00100422\n",
      "[300]\ttraining's l2: 0.0188573\tvalid_1's l2: 0.00018907\n",
      "[400]\ttraining's l2: 0.0155622\tvalid_1's l2: 9.34996e-06\n",
      "Early stopping, best iteration is:\n",
      "[396]\ttraining's l2: 0.0156712\tvalid_1's l2: 5.94291e-06\n",
      "1.0\n",
      "valid mean: 657.9859664471652\n",
      "true  mean: 657.980303030303\n",
      "test  mean: 539.1675313275712\n",
      "(1320, 2)\n"
     ]
    }
   ],
   "source": [
    "def score(data, pred='pred_label', label='label', group='model'):\n",
    "    data['pred_label'] = data['pred_label'].apply(lambda x: 0 if x < 0 else x).round().astype(int)\n",
    "    data_agg = data.groupby('model').agg({\n",
    "        pred:  list,\n",
    "        label: [list, 'mean']\n",
    "    }).reset_index()\n",
    "    data_agg.columns = ['_'.join(col).strip() for col in data_agg.columns]\n",
    "    nrmse_score = []\n",
    "    for raw in data_agg[['{0}_list'.format(pred), '{0}_list'. format(label), '{0}_mean'.format(label)]].values:\n",
    "        nrmse_score.append(mse(raw[0], raw[1]) ** 0.5 / raw[2] )\n",
    "    print(1 - np.mean(nrmse_score))\n",
    "    return 1 - np.mean(nrmse_score)\n",
    "def get_model_type(train_x,train_y,valid_x,valid_y,m_type='lgb',i=0):   \n",
    "    if m_type == 'lgb':\n",
    "        model = lgb.LGBMRegressor(\n",
    "                                num_leaves=2**5-1, reg_alpha=0.25, reg_lambda=0.25, objective='mse',\n",
    "                                max_depth=-1, learning_rate=0.05, min_child_samples=10, random_state=2019,\n",
    "                                n_estimators=2000, subsample=0.9, colsample_bytree=0.7,num_threads= -1,\n",
    "                                )\n",
    "        model.fit(train_x, train_y, \n",
    "              eval_set=[(train_x, train_y),(valid_x, valid_y)], \n",
    "              categorical_feature=cate_feat, \n",
    "              early_stopping_rounds=100, verbose=100)\n",
    "    elif m_type == 'xgb':\n",
    "        model = xgb.XGBRegressor(\n",
    "                                max_depth=5 , learning_rate=0.05, n_estimators=2000, \n",
    "                                objective='reg:gamma', tree_method = 'hist',subsample=0.9, \n",
    "                                colsample_bytree=0.7, min_child_samples=5,eval_metric = 'rmse' \n",
    "                                )\n",
    "        model.fit(train_x, train_y, \n",
    "              eval_set=[(train_x, train_y),(valid_x, valid_y)], \n",
    "              early_stopping_rounds=100, verbose=100)   \n",
    "    return model\n",
    "def get_train_model(df_, m, m_type='lgb',i=0):\n",
    "    df = df_.copy()\n",
    "    # 数据集划分m=25,26,27,28,\n",
    "    st = 13#start time \n",
    "    all_idx   = (df['mt'].between(st , m-1))\n",
    "    train_idx = (df['mt'].between(st , m-4))\n",
    "    valid_idx = (df['mt'].between(m-3, m-3))\n",
    "    test_idx  = (df['mt'].between(m  , m  ))\n",
    "    # 最终确认\n",
    "    train_x = df[train_idx][features]\n",
    "    train_y = df[train_idx]['n_label']\n",
    "    valid_x = df[valid_idx][features]\n",
    "    valid_y = df[valid_idx]['n_label']   \n",
    "    # get model\n",
    "    model = get_model_type(train_x,train_y,valid_x,valid_y,m_type,i)  \n",
    "    # offline\n",
    "    df['pred_label'] = np.expm1(model.predict(df[features]))\n",
    "    best_score = score(df[valid_idx]) \n",
    "    # online\n",
    "    if m_type == 'lgb':\n",
    "        model.n_estimators = model.best_iteration_ + 100\n",
    "        model.fit(df[all_idx][features], df[all_idx]['n_label'], categorical_feature=cate_feat)\n",
    "    elif m_type == 'xgb':\n",
    "        model.n_estimators = model.best_iteration + 100\n",
    "        model.fit(df[all_idx][features], df[all_idx]['n_label'])\n",
    "    df['forecastVolum'] = np.expm1(model.predict(df[features]))\n",
    "    print('valid mean:',df[valid_idx]['pred_label'].mean())\n",
    "    print('true  mean:',df[valid_idx]['label'].mean())\n",
    "    print('test  mean:',df[test_idx]['forecastVolum'].mean())\n",
    "    # 阶段结果\n",
    "    sub = df[test_idx][['id']]\n",
    "    sub['forecastVolum'] = df[test_idx]['forecastVolum'].apply(lambda x: 0 if x < 0 else x).round().astype(int) \n",
    "    print(sub.shape)\n",
    "    return sub,df[valid_idx]['pred_label']\n",
    "for month in [25,26,27,28]: \n",
    "    m_type = 'lgb' \n",
    "    data['n_label'] = np.log1p(data['label'])\n",
    "    data_df, stat_feat = get_stat_feature(data)#每次都要更新下特征\n",
    "    num_feat = ['regYear'] + stat_feat\n",
    "    cate_feat = ['adcode','bodyType','model','regMonth',]#,'k_mean_1','k_mean'\n",
    "    if m_type == 'lgb':\n",
    "        for i in cate_feat:\n",
    "            data_df[i] = data_df[i].astype('category')\n",
    "    elif m_type == 'xgb':\n",
    "        lbl = LabelEncoder()  \n",
    "        for i in tqdm(cate_feat):\n",
    "            data_df[i] = lbl.fit_transform(data_df[i].astype(str)) \n",
    "    features = num_feat + cate_feat\n",
    "    print(len(features), len(set(features)))   \n",
    "    sub,val_pred = get_train_model(data_df, month, m_type,month-24)   \n",
    "    data.loc[(data.regMonth==(month-24))&(data.regYear==2018), 'salesVolume'] = sub['forecastVolum'].values\n",
    "    data.loc[(data.regMonth==(month-24))&(data.regYear==2018), 'label'      ] = sub['forecastVolum'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "regMonth\n",
      "1    657.980303\n",
      "2    492.591667\n",
      "3    592.658333\n",
      "4    539.158333\n",
      "Name: salesVolume, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "sub = data.loc[(data.regMonth>=1)&(data.regYear==2018), ['id','regMonth','salesVolume']]\n",
    "print(sub.groupby('regMonth')['salesVolume'].mean())\n",
    "sub.columns = ['id','regMonth','forecastVolum']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "regMonth\n",
      "1    514.308333\n",
      "2    383.646970\n",
      "3    462.705303\n",
      "4    420.435606\n",
      "Name: forecastVolum, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "#后处理\n",
    "sub[\"forecastVolum\"]=sub[\"forecastVolum\"]*0.79-5\n",
    "sub[\"forecastVolum\"]=(sub[\"forecastVolum\"]).astype(int)\n",
    "sub.loc[sub[sub[\"forecastVolum\"] < 4].index,\"forecastVolum\"]=4\n",
    "sub.loc[sub[sub[\"forecastVolum\"] >9000].index,\"forecastVolum\"]=9000\n",
    "print(sub.groupby('regMonth')['forecastVolum'].mean())\n",
    "sub.to_csv('lgb_old.csv',index=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
